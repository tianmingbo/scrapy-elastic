2019-11-29 16:36:23 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: zhisousou)
2019-11-29 16:36:23 [scrapy.utils.log] INFO: Versions: lxml 4.3.0.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.4.0, Python 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.6.1, Platform Windows-8.1-6.3.9600-SP0
2019-11-29 16:36:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'zhisousou', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'logs\\zhisousou\\zhilian\\51fb6810128311ea80c91008b155e770.log', 'NEWSPIDER_MODULE': 'zhisousou.spiders', 'SPIDER_MODULES': ['zhisousou.spiders']}
2019-11-29 16:36:23 [scrapy.extensions.telnet] INFO: Telnet Password: 8dd9948f3f3966a8
2019-11-29 16:36:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-11-29 16:36:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "firefox", "acceptInsecureCerts": true}}, "desiredCapabilities": {"browserName": "firefox", "acceptInsecureCerts": true, "marionette": true}}
2019-11-29 16:36:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:54302
2019-11-29 16:36:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session HTTP/1.1" 200 735
2019-11-29 16:36:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:36:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'zhisousou.middlewares.ZhisousouDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-29 16:36:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-29 16:36:33 [scrapy.middleware] INFO: Enabled item pipelines:
['zhisousou.pipelines.ZhisousouPipeline']
2019-11-29 16:36:33 [scrapy.core.engine] INFO: Spider opened
2019-11-29 16:36:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-29 16:36:33 [zhilian] INFO: Spider opened: zhilian
2019-11-29 16:36:33 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-29 16:36:33 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "http://zhaopin.com/"}
2019-11-29 16:36:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:36:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:36:43 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:36:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 200 173306
2019-11-29 16:36:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:36:43 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {}
2019-11-29 16:36:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 36
2019-11-29 16:36:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:36:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://zhaopin.com/> (referer: None)
2019-11-29 16:36:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://sou.zhaopin.com/?jl=635&kw=Python&kt=3&sf=0&st=0"}
2019-11-29 16:36:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:36:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:36:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:36:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 200 936470
2019-11-29 16:36:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:36:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {}
2019-11-29 16:36:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 68
2019-11-29 16:36:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:36:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sou.zhaopin.com/?jl=635&kw=Python&kt=3&sf=0&st=0> (referer: https://www.zhaopin.com/)
2019-11-29 16:36:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC508620126J00456780105.htm"}
2019-11-29 16:36:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:36:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:36:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:36:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 200 101601
2019-11-29 16:36:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:36:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {}
2019-11-29 16:36:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 64
2019-11-29 16:36:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:36:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jobs.zhaopin.com/CC508620126J00456780105.htm> (referer: https://sou.zhaopin.com/?jl=635&sf=0&st=0&kw=Python&kt=3)
2019-11-29 16:36:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC340780835J00269329404.htm"}
2019-11-29 16:36:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:36:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:36:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:36:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 200 247670
2019-11-29 16:36:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:36:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {}
2019-11-29 16:36:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 64
2019-11-29 16:36:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:36:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jobs.zhaopin.com/CC340780835J00269329404.htm> (referer: https://sou.zhaopin.com/?jl=635&sf=0&st=0&kw=Python&kt=3)
2019-11-29 16:36:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC383859710J00250641904.htm"}
2019-11-29 16:36:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:36:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:36:58 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:36:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 200 244348
2019-11-29 16:36:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:36:58 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {}
2019-11-29 16:36:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 64
2019-11-29 16:36:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:36:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jobs.zhaopin.com/CC383859710J00250641904.htm> (referer: https://sou.zhaopin.com/?jl=635&sf=0&st=0&kw=Python&kt=3)
2019-11-29 16:36:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC628583138J00216661602.htm"}
2019-11-29 16:37:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:37:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:03 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:37:03 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 200 261041
2019-11-29 16:37:03 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:03 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {}
2019-11-29 16:37:03 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 64
2019-11-29 16:37:03 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jobs.zhaopin.com/CC628583138J00216661602.htm> (referer: https://sou.zhaopin.com/?jl=635&sf=0&st=0&kw=Python&kt=3)
2019-11-29 16:37:03 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC201489335J00191776006.htm"}
2019-11-29 16:37:05 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:37:05 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:07 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:37:07 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 200 249526
2019-11-29 16:37:07 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:07 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {}
2019-11-29 16:37:07 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 64
2019-11-29 16:37:07 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jobs.zhaopin.com/CC201489335J00191776006.htm> (referer: https://sou.zhaopin.com/?jl=635&sf=0&st=0&kw=Python&kt=3)
2019-11-29 16:37:07 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC632690830J00186373512.htm"}
2019-11-29 16:37:08 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:37:08 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:10 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:37:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 200 244078
2019-11-29 16:37:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:10 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {}
2019-11-29 16:37:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 64
2019-11-29 16:37:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jobs.zhaopin.com/CC632690830J00186373512.htm> (referer: https://sou.zhaopin.com/?jl=635&sf=0&st=0&kw=Python&kt=3)
2019-11-29 16:37:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC000542945J00453438105.htm"}
2019-11-29 16:37:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:37:11 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:13 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:37:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 200 244403
2019-11-29 16:37:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:13 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {}
2019-11-29 16:37:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 64
2019-11-29 16:37:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jobs.zhaopin.com/CC000542945J00453438105.htm> (referer: https://sou.zhaopin.com/?jl=635&sf=0&st=0&kw=Python&kt=3)
2019-11-29 16:37:13 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/305934717250402.htm"}
2019-11-29 16:37:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:37:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:16 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:37:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 200 251564
2019-11-29 16:37:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:16 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {}
2019-11-29 16:37:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 56
2019-11-29 16:37:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jobs.zhaopin.com/305934717250402.htm> (referer: https://sou.zhaopin.com/?jl=635&sf=0&st=0&kw=Python&kt=3)
2019-11-29 16:37:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC120921762J00461062301.htm"}
2019-11-29 16:37:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:37:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:19 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:37:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 200 241564
2019-11-29 16:37:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:19 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {}
2019-11-29 16:37:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 64
2019-11-29 16:37:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jobs.zhaopin.com/CC120921762J00461062301.htm> (referer: https://sou.zhaopin.com/?jl=635&sf=0&st=0&kw=Python&kt=3)
2019-11-29 16:37:19 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC632690830J00186375712.htm"}
2019-11-29 16:37:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:37:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:22 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:37:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 200 251556
2019-11-29 16:37:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:22 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {}
2019-11-29 16:37:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 64
2019-11-29 16:37:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jobs.zhaopin.com/CC632690830J00186375712.htm> (referer: https://sou.zhaopin.com/?jl=635&sf=0&st=0&kw=Python&kt=3)
2019-11-29 16:37:22 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC632690830J00177962512.htm"}
2019-11-29 16:37:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:37:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:24 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:37:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 200 244859
2019-11-29 16:37:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:24 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {}
2019-11-29 16:37:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 64
2019-11-29 16:37:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jobs.zhaopin.com/CC632690830J00177962512.htm> (referer: https://sou.zhaopin.com/?jl=635&sf=0&st=0&kw=Python&kt=3)
2019-11-29 16:37:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC632690830J00186377112.htm"}
2019-11-29 16:37:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:37:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:28 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:37:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 200 250321
2019-11-29 16:37:28 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:28 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {}
2019-11-29 16:37:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 64
2019-11-29 16:37:28 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jobs.zhaopin.com/CC632690830J00186377112.htm> (referer: https://sou.zhaopin.com/?jl=635&sf=0&st=0&kw=Python&kt=3)
2019-11-29 16:37:28 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC842910190J00180735304.htm"}
2019-11-29 16:37:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:37:28 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:30 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:37:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 200 256573
2019-11-29 16:37:31 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:31 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {}
2019-11-29 16:37:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 64
2019-11-29 16:37:31 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jobs.zhaopin.com/CC842910190J00180735304.htm> (referer: https://sou.zhaopin.com/?jl=635&sf=0&st=0&kw=Python&kt=3)
2019-11-29 16:37:31 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC842910190J00176419004.htm"}
2019-11-29 16:37:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:37:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:35 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:37:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 200 269532
2019-11-29 16:37:35 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:35 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {}
2019-11-29 16:37:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 64
2019-11-29 16:37:35 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jobs.zhaopin.com/CC842910190J00176419004.htm> (referer: https://sou.zhaopin.com/?jl=635&sf=0&st=0&kw=Python&kt=3)
2019-11-29 16:37:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC872325800J00367286705.htm"}
2019-11-29 16:37:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:37:36 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:38 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:37:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 200 243152
2019-11-29 16:37:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:38 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {}
2019-11-29 16:37:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 64
2019-11-29 16:37:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://jobs.zhaopin.com/CC872325800J00367286705.htm> (referer: https://sou.zhaopin.com/?jl=635&sf=0&st=0&kw=Python&kt=3)
2019-11-29 16:37:38 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC230292410J00143370213.htm"}
2019-11-29 16:37:39 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 200 14
2019-11-29 16:37:39 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:41 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/source {}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "GET /session/fdb7d37a-28dd-4563-908c-4347aaedf287/source HTTP/1.1" 500 105
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC508620126J00431691105.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC831497740J00382125407.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC160261813J00344398806.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC268447232J00310766904.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC120107107J00175069414.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC420498919J00318289704.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC142331073J00224111604.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC613516730J00140848702.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/399612635356627.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC508620126J00466404205.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC447954822J00442165203.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC134189873J00343208004.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC508620126J00433197105.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC367075483J00354346805.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC447954822J00409370703.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/457408237250035.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC824472920J00332944005.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC297085182J00440931007.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC000023354J00190524013.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC623461580J00407689207.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CCL1203372320J00362190302.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC599476231J00380747408.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC599476231J00380747308.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CCL1213923340J00207119009.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC896620630J00375792208.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC872220650J00199877409.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC862648410J00371601502.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC864094980J00435125803.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CCL1218825980J00459728307.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC470601732J00357901506.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC692695929J00472420401.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC645051428J00476628005.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC260972586J00326721903.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CZ829190630J00134964912.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC813110400J00461066101.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC645051428J00386044905.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC831062620J00390293707.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC143712520J00436820305.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC631016382J00443746507.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC569576922J00429457005.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC508620126J00335679405.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC120107107J00183057614.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC120107107J00197429814.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC678545520J00190671112.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC142715590J00367419908.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC120107107J00197429714.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC545530129J00246780105.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC120107107J00183057514.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC678545520J00160239312.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC120107107J00076770814.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC196911813J00137056915.htm"}
2019-11-29 16:37:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:37:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:37:54 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 17 pages/min), scraped 0 items (at 0 items/min)
2019-11-29 16:37:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC142331073J00224111604.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:37:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC420498919J00318289704.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:37:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC120107107J00175069414.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:37:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC230292410J00143370213.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 96, in process_request
    source = self.driver.page_source
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: Failed to decode response from marionette

2019-11-29 16:37:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC160261813J00344398806.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:37:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC831497740J00382125407.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:37:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC508620126J00431691105.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:37:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC268447232J00310766904.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:37:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:37:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): localhost:9200
2019-11-29 16:37:56 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.016s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4DD4E6D8>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:37:56 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:37:56 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:37:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (2): localhost:9200
2019-11-29 16:37:58 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.047s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4DD4E748>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:37:58 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:37:58 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:37:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (3): localhost:9200
2019-11-29 16:38:00 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.047s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4DD4E6A0>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:00 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:00 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (4): localhost:9200
2019-11-29 16:38:02 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.047s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4DD4E780>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:02 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:02 [scrapy.core.scraper] ERROR: Error processing {'company_name': [''],
 'company_url': ['http://company.zhaopin.com/CZ508620120.htm'],
 'degree_need': [''],
 'job_advantage': [''],
 'job_city': [''],
 'job_need': ['<div class="describtion__detail-content"><div> '
              '1.</div><div> 2. '
              '</div><div> 3. '
              '</div><div> </div><div> '
              'pythonJava</div></div>'],
 'job_responsibility': [''],
 'job_type': [''],
 'job_url': [''],
 'publish_time': ['14:53'],
 'salary': [''],
 'title': ['Python'],
 'work_years': ['1-3']}
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4DD4E780>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\pipelines.py", line 12, in process_item
    item.save_to_es()
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 57, in save_to_es
    job.suggest = gen_suggests(JobType._doc_type.index, ((job.title, 10), (job.job_city, 7)))
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 73, in gen_suggests
    words = es.indices.analyze(index=index, analyzer="ik_max_word", params={'filter': ["lowercase"]}, body=text)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "g:\anaconda\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 124, in perform_request
    raise ConnectionError('N/A', str(e), e)
elasticsearch.exceptions.ConnectionError: ConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4DD4E780>: Failed to establish a new connection: [WinError 10061] ) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4DD4E780>: Failed to establish a new connection: [WinError 10061] )
2019-11-29 16:38:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC508620126J00466404205.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC447954822J00442165203.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC508620126J00433197105.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/399612635356627.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC613516730J00140848702.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC134189873J00343208004.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC191215511J00310135408.htm"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC826330310J00327011508.htm"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC120914506J00446169003.htm"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC640402330J00378495702.htm"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC528943025J00441993307.htm"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC542445930J00376959002.htm"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CCL1222977140J00450113003.htm"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://xiaoyuan.zhaopin.com/job/CC000117819J90001986000?from=sz"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CZ594912420J00305115703.htm"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CZ185718010J00196024502.htm"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC465341913J00108419313.htm"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC645926286J00260826405.htm"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC833252140J00274344707.htm"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC833252140J00289577007.htm"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CZ697762580J00254850503.htm"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC250519519J00365838608.htm"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC219838732J00353649002.htm"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC219838732J00353648902.htm"}
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:38:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:38:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC824472920J00332944005.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC447954822J00409370703.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/457408237250035.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC367075483J00354346805.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC297085182J00440931007.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:02 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (5): localhost:9200
2019-11-29 16:38:04 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4DD7D5F8>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:04 [elasticsearch] DEBUG: > ["python"]
2019-11-29 16:38:04 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (6): localhost:9200
2019-11-29 16:38:06 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4C18>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:06 [elasticsearch] DEBUG: > ["python"]
2019-11-29 16:38:06 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (7): localhost:9200
2019-11-29 16:38:08 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.016s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4B70>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:08 [elasticsearch] DEBUG: > ["python"]
2019-11-29 16:38:08 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (8): localhost:9200
2019-11-29 16:38:10 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.000s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4D30>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:10 [elasticsearch] DEBUG: > ["python"]
2019-11-29 16:38:10 [scrapy.core.scraper] ERROR: Error processing {'company_name': [''],
 'company_url': ['http://company.zhaopin.com/CZ340780830.htm'],
 'degree_need': ['3-5'],
 'job_advantage': [',,,,'],
 'job_city': [''],
 'job_need': ['<div '
              'class="describtion__detail-content"><div></div><div>1</div><div>2Devops</div><div>3</div><div>4</div><div>5python</div><div></div><div>1.</div><div>2.Git,GOPython</div><div>3.JavascriptCSShtml;</div><div>4.</div><div>5.LinuxCentOSubuntuRedHat,TCP/IP</div><div>6.</div><div>7.MySQLRedisMongodb</div><div>8.K8S/IstioEnvoy</div><div>8.</div><div>9.DevOpsDevOps;</div><div>10.</div></div>'],
 'job_responsibility': [''],
 'job_type': [''],
 'job_url': [''],
 'publish_time': ['1125'],
 'salary': ['8-1'],
 'title': ['python'],
 'work_years': ['']}
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4D30>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\pipelines.py", line 12, in process_item
    item.save_to_es()
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 57, in save_to_es
    job.suggest = gen_suggests(JobType._doc_type.index, ((job.title, 10), (job.job_city, 7)))
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 73, in gen_suggests
    words = es.indices.analyze(index=index, analyzer="ik_max_word", params={'filter': ["lowercase"]}, body=text)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "g:\anaconda\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 124, in perform_request
    raise ConnectionError('N/A', str(e), e)
elasticsearch.exceptions.ConnectionError: ConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5A4D30>: Failed to establish a new connection: [WinError 10061] ) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5A4D30>: Failed to establish a new connection: [WinError 10061] )
2019-11-29 16:38:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC000023354J00190524013.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CCL1218825980J00459728307.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC864094980J00435125803.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC862648410J00371601502.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC872220650J00199877409.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC896620630J00375792208.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CCL1213923340J00207119009.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC599476231J00380747308.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC599476231J00380747408.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CCL1203372320J00362190302.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC623461580J00407689207.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:10 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (9): localhost:9200
2019-11-29 16:38:12 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.040s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4E48>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:12 [elasticsearch] DEBUG: > ["python"]
2019-11-29 16:38:12 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (10): localhost:9200
2019-11-29 16:38:14 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.000s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5BD9E8>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:14 [elasticsearch] DEBUG: > ["python"]
2019-11-29 16:38:14 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (11): localhost:9200
2019-11-29 16:38:16 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.000s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5BD208>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:16 [elasticsearch] DEBUG: > ["python"]
2019-11-29 16:38:16 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (12): localhost:9200
2019-11-29 16:38:18 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.000s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5BDB70>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:18 [elasticsearch] DEBUG: > ["python"]
2019-11-29 16:38:18 [scrapy.core.scraper] ERROR: Error processing {'company_name': [''],
 'company_url': ['http://company.zhaopin.com/CZ383859710.htm'],
 'degree_need': [''],
 'job_advantage': [',,,,,,'],
 'job_city': [''],
 'job_need': ['<div '
              'class="describtion__detail-content"><div><h3></h3><ul><li></li><li></li><li>App</li><li></li></ul><h3></h3><ul><li> '
              'Python '
              '</li><li>,,</li><li>MySQL</li><li>Linux</li><li>OCR</li><li></li><li>(HDFS/Elasticsearch/HBase/Redis/Spark)</li></ul></div></div>'],
 'job_responsibility': [''],
 'job_type': [''],
 'job_url': [''],
 'publish_time': ['1114'],
 'salary': ['8-1'],
 'title': ['python'],
 'work_years': ['1-3']}
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5BDB70>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\pipelines.py", line 12, in process_item
    item.save_to_es()
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 57, in save_to_es
    job.suggest = gen_suggests(JobType._doc_type.index, ((job.title, 10), (job.job_city, 7)))
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 73, in gen_suggests
    words = es.indices.analyze(index=index, analyzer="ik_max_word", params={'filter': ["lowercase"]}, body=text)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "g:\anaconda\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 124, in perform_request
    raise ConnectionError('N/A', str(e), e)
elasticsearch.exceptions.ConnectionError: ConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5BDB70>: Failed to establish a new connection: [WinError 10061] ) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5BDB70>: Failed to establish a new connection: [WinError 10061] )
2019-11-29 16:38:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC813110400J00461066101.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CZ829190630J00134964912.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC260972586J00326721903.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC645051428J00476628005.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC470601732J00357901506.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC692695929J00472420401.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:18 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (13): localhost:9200
2019-11-29 16:38:20 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4DA0>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:20 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:20 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (14): localhost:9200
2019-11-29 16:38:22 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.000s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4C18>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:22 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:22 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (15): localhost:9200
2019-11-29 16:38:24 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.000s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4CF8>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:24 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:24 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (16): localhost:9200
2019-11-29 16:38:26 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5BDDD8>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:26 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:26 [scrapy.core.scraper] ERROR: Error processing {'company_name': [''],
 'company_url': ['http://company.zhaopin.com/CC628583138.htm'],
 'degree_need': [''],
 'job_advantage': [',,,,,,,'],
 'job_city': [''],
 'job_need': ['<div class="describtion__detail-content"><p style="box-sizing: '
              'border-box; font-family: ; margin-bottom: 0px; border: 0px; '
              'color: rgb(51, 51, 51);"><br style="box-sizing: '
              'border-box;"></p><p style="box-sizing: border-box; font-family: '
              '; margin-bottom: 0px; border: 0px; color: rgb(51, 51, '
              '51);">1</p><p style="box-sizing: border-box; '
              'font-family: ; margin-bottom: 0px; border: 0px; color: '
              'rgb(51, 51, 51);">2</p><p '
              'style="box-sizing: border-box; font-family: ; '
              'margin-bottom: 0px; border: 0px; color: rgb(51, 51, '
              '51);">3</p><p style="box-sizing: '
              'border-box; font-family: ; margin-bottom: 0px; border: 0px; '
              'color: rgb(51, 51, 51);">\xa0</p><p style="box-sizing: '
              'border-box; font-family: ; margin-bottom: 0px; border: 0px; '
              'color: rgb(51, 51, 51);"></p><p style="box-sizing: '
              'border-box; font-family: ; margin-bottom: 0px; border: 0px; '
              'color: rgb(51, 51, '
              '51);">1.</p><p '
              'style="box-sizing: border-box; font-family: ; '
              'margin-bottom: 0px; border: 0px; color: rgb(51, 51, '
              '51);">2.</p><p style="box-sizing: border-box; '
              'font-family: ; margin-bottom: 0px; border: 0px; color: '
              'rgb(51, 51, 51);">3. </p><p '
              'style="box-sizing: border-box; font-family: ; '
              'margin-bottom: 0px; border: 0px; color: rgb(51, 51, 51);">4. '
              '</p><p style="box-sizing: border-box; '
              'font-family: ; margin-bottom: 0px; border: 0px; color: '
              'rgb(51, 51, 51);">5. \xa0</p><p '
              'style="box-sizing: border-box; font-family: ; '
              'margin-bottom: 0px; border: 0px; color: rgb(51, 51, 51);">\xa0'
              '</p><p style="box-sizing: border-box; font-family: ; '
              'margin-bottom: 0px; border: 0px; color: rgb(51, 51, '
              '51);"></p><p style="box-sizing: border-box; font-family: '
              '; margin-bottom: 0px; border: 0px; color: rgb(51, 51, '
              '51);">1</p><p style="box-sizing: border-box; '
              'font-family: ; margin-bottom: 0px; border: 0px; color: '
              'rgb(51, 51, 51);">25</p><span '
              'style="color: rgb(51, 51, 51); font-family: ; font-style: '
              'normal; font-weight: 400;">3</span></div>'],
 'job_responsibility': [''],
 'job_type': [''],
 'job_url': [''],
 'publish_time': ['1115'],
 'salary': ['2-4'],
 'title': ['Python'],
 'work_years': ['']}
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5BDDD8>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\pipelines.py", line 12, in process_item
    item.save_to_es()
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 57, in save_to_es
    job.suggest = gen_suggests(JobType._doc_type.index, ((job.title, 10), (job.job_city, 7)))
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 73, in gen_suggests
    words = es.indices.analyze(index=index, analyzer="ik_max_word", params={'filter': ["lowercase"]}, body=text)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "g:\anaconda\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 124, in perform_request
    raise ConnectionError('N/A', str(e), e)
elasticsearch.exceptions.ConnectionError: ConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5BDDD8>: Failed to establish a new connection: [WinError 10061] ) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5BDDD8>: Failed to establish a new connection: [WinError 10061] )
2019-11-29 16:38:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC120107107J00197429814.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC120107107J00183057614.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC508620126J00335679405.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC569576922J00429457005.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC631016382J00443746507.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC143712520J00436820305.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC831062620J00390293707.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC645051428J00386044905.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC120107107J00183057514.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC196911813J00137056915.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC120107107J00076770814.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC678545520J00160239312.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC545530129J00246780105.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC120107107J00197429714.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC142715590J00367419908.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC678545520J00190671112.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:38:26 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (17): localhost:9200
2019-11-29 16:38:28 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5BDEB8>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:28 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:28 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (18): localhost:9200
2019-11-29 16:38:30 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.047s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C4C88>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:30 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:30 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (19): localhost:9200
2019-11-29 16:38:32 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C4BE0>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:32 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:32 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (20): localhost:9200
2019-11-29 16:38:34 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.047s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C4DA0>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:34 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:34 [scrapy.core.scraper] ERROR: Error processing {'company_name': [''],
 'company_url': ['http://company.zhaopin.com/CZ201489330.htm'],
 'degree_need': [''],
 'job_advantage': ['14,,,,,,,'],
 'job_city': [''],
 'job_need': ['<div '
              'class="describtion__detail-content"><div></div><div>1.<br>2.<br>3.</div><div>4.python<br></div><div></div><div>1. '
              '<br>2. WebPython '
              'WebTornadoDjangoFlask)<br>3. '
              'pythonC#javaC#java<br>4. '
              '<br></div><div><br></div></div>'],
 'job_responsibility': [''],
 'job_type': [''],
 'job_url': [''],
 'publish_time': ['1128'],
 'salary': ['6-8'],
 'title': ['Python'],
 'work_years': ['1-3']}
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C4DA0>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\pipelines.py", line 12, in process_item
    item.save_to_es()
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 57, in save_to_es
    job.suggest = gen_suggests(JobType._doc_type.index, ((job.title, 10), (job.job_city, 7)))
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 73, in gen_suggests
    words = es.indices.analyze(index=index, analyzer="ik_max_word", params={'filter': ["lowercase"]}, body=text)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "g:\anaconda\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 124, in perform_request
    raise ConnectionError('N/A', str(e), e)
elasticsearch.exceptions.ConnectionError: ConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5C4DA0>: Failed to establish a new connection: [WinError 10061] ) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5C4DA0>: Failed to establish a new connection: [WinError 10061] )
2019-11-29 16:38:34 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (21): localhost:9200
2019-11-29 16:38:36 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.047s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C4EB8>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:36 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:36 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (22): localhost:9200
2019-11-29 16:38:39 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C8240>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:39 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:39 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (23): localhost:9200
2019-11-29 16:38:41 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.047s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C80B8>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:41 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:41 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (24): localhost:9200
2019-11-29 16:38:43 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.047s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C8438>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:43 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:43 [scrapy.core.scraper] ERROR: Error processing {'company_name': [''],
 'company_url': ['http://special.zhaopin.com/pagepublish/63269083/index.html'],
 'degree_need': [''],
 'job_advantage': [',,14,,,,,'],
 'job_city': [''],
 'job_need': ['<div class="describtion__detail-content"><p> '
              '</p><p>2012+</p><p></p><p>10</p><p></p><p></p><p><br></p><p></p><p>1PBL(Problem '
              'Based '
              'Learning)</p><p>2 '
              '</p><p>3</p><p>4 '
              '</p><div>  '
              '<br></div><p></p><p>1</p><p>2</p><p>3</p><p>4</p><p><br></p><p> '
              '</p><p>1200/</p><p>2</p><p></p><p>3</p><p><br></p><p></p></div>'],
 'job_responsibility': [''],
 'job_type': [''],
 'job_url': [''],
 'publish_time': ['09:49'],
 'salary': ['6-8'],
 'title': ['Python'],
 'work_years': ['']}
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C8438>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\pipelines.py", line 12, in process_item
    item.save_to_es()
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 57, in save_to_es
    job.suggest = gen_suggests(JobType._doc_type.index, ((job.title, 10), (job.job_city, 7)))
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 73, in gen_suggests
    words = es.indices.analyze(index=index, analyzer="ik_max_word", params={'filter': ["lowercase"]}, body=text)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "g:\anaconda\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 124, in perform_request
    raise ConnectionError('N/A', str(e), e)
elasticsearch.exceptions.ConnectionError: ConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5C8438>: Failed to establish a new connection: [WinError 10061] ) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5C8438>: Failed to establish a new connection: [WinError 10061] )
2019-11-29 16:38:43 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (25): localhost:9200
2019-11-29 16:38:45 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.039s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C4E10>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:45 [elasticsearch] DEBUG: > ["c/c++/python____"]
2019-11-29 16:38:45 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (26): localhost:9200
2019-11-29 16:38:47 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C4C88>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:47 [elasticsearch] DEBUG: > ["c/c++/python____"]
2019-11-29 16:38:47 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (27): localhost:9200
2019-11-29 16:38:49 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C4E48>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:49 [elasticsearch] DEBUG: > ["c/c++/python____"]
2019-11-29 16:38:49 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (28): localhost:9200
2019-11-29 16:38:51 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.047s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C4D30>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:51 [elasticsearch] DEBUG: > ["c/c++/python____"]
2019-11-29 16:38:51 [scrapy.core.scraper] ERROR: Error processing {'company_name': [''],
 'company_url': ['http://company.zhaopin.com/CC000542945.htm'],
 'degree_need': [''],
 'job_advantage': [',,'],
 'job_city': [''],
 'job_need': ['<div class="describtion__detail-content"><div> '
              '</div><div> '
              '1C/C++/Python</div><div> '
              '2</div><div> '
              '</div><div> '
              '1</div><div> '
              '2c/c++</div><div> '
              '</div><div> '
              '1SDKAPI</div><div> '
              '2VRP</div><div> '
              '3</div><div> '
              '4VRP</div></div>'],
 'job_responsibility': [''],
 'job_type': [''],
 'job_url': [''],
 'publish_time': ['109'],
 'salary': [''],
 'title': ['c/c++/python____'],
 'work_years': ['1-3']}
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C4D30>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\pipelines.py", line 12, in process_item
    item.save_to_es()
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 57, in save_to_es
    job.suggest = gen_suggests(JobType._doc_type.index, ((job.title, 10), (job.job_city, 7)))
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 73, in gen_suggests
    words = es.indices.analyze(index=index, analyzer="ik_max_word", params={'filter': ["lowercase"]}, body=text)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "g:\anaconda\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 124, in perform_request
    raise ConnectionError('N/A', str(e), e)
elasticsearch.exceptions.ConnectionError: ConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5C4D30>: Failed to establish a new connection: [WinError 10061] ) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5C4D30>: Failed to establish a new connection: [WinError 10061] )
2019-11-29 16:38:51 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (29): localhost:9200
2019-11-29 16:38:53 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5BDEB8>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:53 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:53 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (30): localhost:9200
2019-11-29 16:38:55 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4828>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:55 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:55 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (31): localhost:9200
2019-11-29 16:38:57 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A47B8>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:57 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:57 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (32): localhost:9200
2019-11-29 16:38:59 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4E80>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:38:59 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:38:59 [scrapy.core.scraper] ERROR: Error processing {'company_name': [''],
 'company_url': ['http://special.zhaopin.com/pagepublish/30593471/index.html'],
 'degree_need': [''],
 'job_advantage': [',,,,,,,'],
 'job_city': [''],
 'job_need': ['<div '
              'class="describtion__detail-content"><p><br></p><p>1Python '
              'Web</p><p>2</p><p>3</p><p>4</p><p></p><p>13Web</p><p>2PythonWebDjangoFlask</p><p>3SQL</p><p>4Linux</p><p>4Web+A1:D6</p><p>5</p><p>6Redis, '
              'Celery, Docker</p><p>7Git</p><p>8Rest '
              'API</p><p>9</p><p>10</p></div>'],
 'job_responsibility': [''],
 'job_type': [''],
 'job_url': [''],
 'publish_time': ['1125'],
 'salary': ['9-1.8'],
 'title': ['Python'],
 'work_years': ['']}
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4E80>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\pipelines.py", line 12, in process_item
    item.save_to_es()
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 57, in save_to_es
    job.suggest = gen_suggests(JobType._doc_type.index, ((job.title, 10), (job.job_city, 7)))
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 73, in gen_suggests
    words = es.indices.analyze(index=index, analyzer="ik_max_word", params={'filter': ["lowercase"]}, body=text)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "g:\anaconda\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 124, in perform_request
    raise ConnectionError('N/A', str(e), e)
elasticsearch.exceptions.ConnectionError: ConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5A4E80>: Failed to establish a new connection: [WinError 10061] ) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5A4E80>: Failed to establish a new connection: [WinError 10061] )
2019-11-29 16:38:59 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:38:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (33): localhost:9200
2019-11-29 16:39:01 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4C88>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:01 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:01 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (34): localhost:9200
2019-11-29 16:39:03 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.016s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C8AC8>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:03 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:03 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (35): localhost:9200
2019-11-29 16:39:05 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.047s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C85C0>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:05 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:05 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (36): localhost:9200
2019-11-29 16:39:07 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C8828>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:07 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:07 [scrapy.core.scraper] ERROR: Error processing {'company_name': [''],
 'company_url': ['http://special.zhaopin.com/pagepublish/12092176/index.html'],
 'degree_need': ['1-3'],
 'job_advantage': [',,,,,,,'],
 'job_city': [''],
 'job_need': ['<div class="describtion__detail-content"><br><ol>  '
              '<li></li>  '
              '<li>Python</li>  '
              '<li>Python/Java</li>  '
              '<li>AI</li></ol><p></p><p></p><ol>  '
              '<li>1Linux pythonPython</li>  '
              '<li>PythonDjangoTornadoFlask</li>  '
              '<li></li>  <li>Java</li>  '
              '<li>git, </li></ol></div>'],
 'job_responsibility': [''],
 'job_type': [''],
 'job_url': [''],
 'publish_time': ['1119'],
 'salary': ['6-1.2'],
 'title': ['Python'],
 'work_years': ['']}
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C8828>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\pipelines.py", line 12, in process_item
    item.save_to_es()
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 57, in save_to_es
    job.suggest = gen_suggests(JobType._doc_type.index, ((job.title, 10), (job.job_city, 7)))
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 73, in gen_suggests
    words = es.indices.analyze(index=index, analyzer="ik_max_word", params={'filter': ["lowercase"]}, body=text)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "g:\anaconda\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 124, in perform_request
    raise ConnectionError('N/A', str(e), e)
elasticsearch.exceptions.ConnectionError: ConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5C8828>: Failed to establish a new connection: [WinError 10061] ) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5C8828>: Failed to establish a new connection: [WinError 10061] )
2019-11-29 16:39:07 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (37): localhost:9200
2019-11-29 16:39:09 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.047s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C8A90>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:09 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:09 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (38): localhost:9200
2019-11-29 16:39:11 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.016s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C8390>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:11 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:11 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (39): localhost:9200
2019-11-29 16:39:13 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.047s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C8518>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:13 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:13 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (40): localhost:9200
2019-11-29 16:39:15 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.019s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C8E48>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:15 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:15 [scrapy.core.scraper] ERROR: Error processing {'company_name': [''],
 'company_url': ['http://special.zhaopin.com/pagepublish/63269083/index.html'],
 'degree_need': [''],
 'job_advantage': ['14,,,,,,'],
 'job_city': [''],
 'job_need': ['<div '
              'class="describtion__detail-content"><p></p><p>2012+</p><p></p><p>10</p><p></p><p></p><p><br></p><p> '
              '</p><p></p><p>1.PBL(Problem-BasedLearning)</p><p>2.////..</p><p>3.. '
              '</p><p>4.</p><p><br></p><p></p><p>1....Python</p><p>2. '
              '</p><p>3.</p><p><br></p><p></p><p>1.</p><p>2.</p><p>3.</p><p>4.</p><p></p><p>/</p></div>'],
 'job_responsibility': [''],
 'job_type': [''],
 'job_url': [''],
 'publish_time': ['09:49'],
 'salary': ['1-1.5'],
 'title': ['Python'],
 'work_years': ['']}
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C8E48>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\pipelines.py", line 12, in process_item
    item.save_to_es()
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 57, in save_to_es
    job.suggest = gen_suggests(JobType._doc_type.index, ((job.title, 10), (job.job_city, 7)))
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 73, in gen_suggests
    words = es.indices.analyze(index=index, analyzer="ik_max_word", params={'filter': ["lowercase"]}, body=text)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "g:\anaconda\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 124, in perform_request
    raise ConnectionError('N/A', str(e), e)
elasticsearch.exceptions.ConnectionError: ConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5C8E48>: Failed to establish a new connection: [WinError 10061] ) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5C8E48>: Failed to establish a new connection: [WinError 10061] )
2019-11-29 16:39:15 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (41): localhost:9200
2019-11-29 16:39:17 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.000s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C8390>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:17 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:17 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (42): localhost:9200
2019-11-29 16:39:19 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.000s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C8160>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:19 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:19 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (43): localhost:9200
2019-11-29 16:39:21 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.000s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C8320>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:21 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:21 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (44): localhost:9200
2019-11-29 16:39:23 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C8C88>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:23 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:23 [scrapy.core.scraper] ERROR: Error processing {'company_name': [''],
 'company_url': ['http://special.zhaopin.com/pagepublish/63269083/index.html'],
 'degree_need': [''],
 'job_advantage': [',,,'],
 'job_city': [''],
 'job_need': ['<div class="describtion__detail-content"><div> '
              '</div><div> '
              '2012+</div><div> '
              '</div><div> '
              '10</div><div> '
              '</div><div> '
              '</div><div> <br></div><div> '
              '</div><div> '
              '1</div><div> '
              '2</div><div> <br></div><div> '
              '</div><div> '
              '1PythonfiddlerCharles</div><div> '
              '2IPXPathAPPScrapy</div><div> '
              '3</div><div> <br></div><div> '
              '</div><div> 1200/</div><div> '
              '2</div><div> '
              '3</div></div>'],
 'job_responsibility': [''],
 'job_type': [''],
 'job_url': [''],
 'publish_time': ['09:49'],
 'salary': ['2-4'],
 'title': ['Python'],
 'work_years': ['']}
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C8C88>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\pipelines.py", line 12, in process_item
    item.save_to_es()
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 57, in save_to_es
    job.suggest = gen_suggests(JobType._doc_type.index, ((job.title, 10), (job.job_city, 7)))
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 73, in gen_suggests
    words = es.indices.analyze(index=index, analyzer="ik_max_word", params={'filter': ["lowercase"]}, body=text)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "g:\anaconda\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 124, in perform_request
    raise ConnectionError('N/A', str(e), e)
elasticsearch.exceptions.ConnectionError: ConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5C8C88>: Failed to establish a new connection: [WinError 10061] ) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5C8C88>: Failed to establish a new connection: [WinError 10061] )
2019-11-29 16:39:23 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (45): localhost:9200
2019-11-29 16:39:25 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.047s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C8908>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:25 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:25 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (46): localhost:9200
2019-11-29 16:39:27 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.016s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4CF8>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:27 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:27 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (47): localhost:9200
2019-11-29 16:39:29 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.016s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4860>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:29 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:29 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (48): localhost:9200
2019-11-29 16:39:31 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.016s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A47B8>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:31 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:31 [scrapy.core.scraper] ERROR: Error processing {'company_name': [''],
 'company_url': ['http://special.zhaopin.com/pagepublish/63269083/index.html'],
 'degree_need': [''],
 'job_advantage': ['14,,,,,,'],
 'job_city': [''],
 'job_need': ['<div '
              'class="describtion__detail-content"><p></p><p>2012+</p><p></p><p>10</p><p></p><p></p><p><br></p><p> '
              '</p><p></p><p>1PBL(Problem Based '
              'Learning)<br>2 '
              '<br>3<br>4 '
              '<br></p><p><br></p><p></p><p>1</p><p>2</p><p>3</p><p>4</p><p><br></p><p></p><p>1.</p><p>2.</p><p>3.</p><p>4.</p><p></p><p>/</p></div>'],
 'job_responsibility': [''],
 'job_type': [''],
 'job_url': [''],
 'publish_time': ['09:49'],
 'salary': ['1-1.5'],
 'title': ['Python'],
 'work_years': ['']}
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A47B8>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\pipelines.py", line 12, in process_item
    item.save_to_es()
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 57, in save_to_es
    job.suggest = gen_suggests(JobType._doc_type.index, ((job.title, 10), (job.job_city, 7)))
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 73, in gen_suggests
    words = es.indices.analyze(index=index, analyzer="ik_max_word", params={'filter': ["lowercase"]}, body=text)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "g:\anaconda\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 124, in perform_request
    raise ConnectionError('N/A', str(e), e)
elasticsearch.exceptions.ConnectionError: ConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5A47B8>: Failed to establish a new connection: [WinError 10061] ) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5A47B8>: Failed to establish a new connection: [WinError 10061] )
2019-11-29 16:39:31 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (49): localhost:9200
2019-11-29 16:39:33 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.047s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4B70>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:33 [elasticsearch] DEBUG: > ["Java/Python-"]
2019-11-29 16:39:33 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (50): localhost:9200
2019-11-29 16:39:36 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C4C88>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:36 [elasticsearch] DEBUG: > ["Java/Python-"]
2019-11-29 16:39:36 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (51): localhost:9200
2019-11-29 16:39:38 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.031s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C4128>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:38 [elasticsearch] DEBUG: > ["Java/Python-"]
2019-11-29 16:39:38 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (52): localhost:9200
2019-11-29 16:39:40 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.047s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C4400>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:40 [elasticsearch] DEBUG: > ["Java/Python-"]
2019-11-29 16:39:40 [scrapy.core.scraper] ERROR: Error processing {'company_name': ['Uniqsys'],
 'company_url': ['http://company.zhaopin.com/CZ842910190.htm'],
 'degree_need': [''],
 'job_advantage': [''],
 'job_city': [''],
 'job_need': ['<div class="describtion__detail-content"><p '
              'class="MsoNormal"><b><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-weight:bold;font-size:12.0000pt;mso-font-kerning:1.0000pt;"></span></b><b><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-weight:bold;font-size:12.0000pt;mso-font-kerning:1.0000pt;"><p></p></span></b></p><p '
              'class="MsoNormal"><b><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-weight:bold;font-size:12.0000pt;mso-font-kerning:1.0000pt;"><p>\xa0'
              '</p></span></b></p><p class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p><p '
              'class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p>\xa0'
              '</p></span></p><p class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p><p '
              'class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;">1<font '
              'face=""></font><font '
              'face="Calibri">3</font><font '
              'face=""></font><font '
              'face="Calibri">2</font><font '
              'face=""></font><font '
              'face="Calibri">2</font><font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p><p '
              'class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;">2<font '
              'face=""></font><font '
              'face="Calibri">2</font><font '
              'face=""></font><font '
              'face="Calibri">JAVA,.NET,C#,C++/C,SAP,PHP,COBOL,IOS,Android,Salesforce,Python,CRM(dynamicsAX)</font><font '
              'face=""></font><font '
              'face="Calibri">oracle</font><font face=""></font><font '
              'face="Calibri">CCNA</font><font face=""></font><font '
              'face="Calibri">CCNP</font><font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p><p '
              'class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;">3<font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p><p '
              'class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;">4<font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p><p '
              'class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p>\xa0'
              '</p></span></p><p class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p><p '
              'class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><font '
              'face=""></font>20<font '
              'face=""></font><font face="Calibri">60</font><font '
              'face=""></font><font face="Calibri">/</font><font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p><p '
              'class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p></div>'],
 'job_responsibility': [''],
 'job_type': [''],
 'job_url': [''],
 'publish_time': ['1128'],
 'salary': ['5-1'],
 'title': ['Java/Python-'],
 'work_years': ['']}
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C4400>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\pipelines.py", line 12, in process_item
    item.save_to_es()
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 57, in save_to_es
    job.suggest = gen_suggests(JobType._doc_type.index, ((job.title, 10), (job.job_city, 7)))
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 73, in gen_suggests
    words = es.indices.analyze(index=index, analyzer="ik_max_word", params={'filter': ["lowercase"]}, body=text)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "g:\anaconda\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 124, in perform_request
    raise ConnectionError('N/A', str(e), e)
elasticsearch.exceptions.ConnectionError: ConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5C4400>: Failed to establish a new connection: [WinError 10061] ) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5C4400>: Failed to establish a new connection: [WinError 10061] )
2019-11-29 16:39:40 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (53): localhost:9200
2019-11-29 16:39:42 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.047s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5C4E48>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:42 [elasticsearch] DEBUG: > ["Java/Python"]
2019-11-29 16:39:42 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (54): localhost:9200
2019-11-29 16:39:44 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.016s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5D7860>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:44 [elasticsearch] DEBUG: > ["Java/Python"]
2019-11-29 16:39:44 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (55): localhost:9200
2019-11-29 16:39:46 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.047s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5D77F0>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:46 [elasticsearch] DEBUG: > ["Java/Python"]
2019-11-29 16:39:46 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (56): localhost:9200
2019-11-29 16:39:48 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.017s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5D79B0>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:48 [elasticsearch] DEBUG: > ["Java/Python"]
2019-11-29 16:39:48 [scrapy.core.scraper] ERROR: Error processing {'company_name': ['Uniqsys'],
 'company_url': ['http://company.zhaopin.com/CZ842910190.htm'],
 'degree_need': [''],
 'job_advantage': [',,,,,,,'],
 'job_city': [''],
 'job_need': ['<div class="describtion__detail-content"><p '
              'class="MsoNormal"><b><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-weight:bold;font-size:12.0000pt;mso-font-kerning:1.0000pt;"></span></b><b><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-weight:bold;font-size:12.0000pt;mso-font-kerning:1.0000pt;"><p></p></span></b></p><p '
              'class="MsoNormal"><b><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-weight:bold;font-size:12.0000pt;mso-font-kerning:1.0000pt;"><p>\xa0'
              '</p></span></b></p><p class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p><p '
              'class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p>\xa0'
              '</p></span></p><p class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p><p '
              'class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;">1<font '
              'face=""></font><font '
              'face="Calibri">3</font><font '
              'face=""></font><font '
              'face="Calibri">2</font><font '
              'face=""></font><font '
              'face="Calibri">2</font><font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p><p '
              'class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;">2<font '
              'face=""></font><font '
              'face="Calibri">2</font><font '
              'face=""></font><font '
              'face="Calibri">JAVA,.NET,C#,C++/C,SAP,PHP,COBOL,IOS,Android,Salesforce,Python,CRM(dynamicsAX)</font><font '
              'face=""></font><font '
              'face="Calibri">oracle</font><font face=""></font><font '
              'face="Calibri">CCNA</font><font face=""></font><font '
              'face="Calibri">CCNP</font><font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p><p '
              'class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;">3<font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p><p '
              'class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;">4<font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p><p '
              'class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p>\xa0'
              '</p></span></p><p class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p><p '
              'class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><font '
              'face=""></font>20<font '
              'face=""></font><font face="Calibri">60</font><font '
              'face=""></font><font face="Calibri">/</font><font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p><p '
              'class="MsoNormal"><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><font '
              'face=""></font></span><span '
              'style="mso-spacerun:\'yes\';font-family:;mso-ascii-font-family:Calibri;mso-hansi-font-family:Calibri;mso-bidi-font-family:\'Times '
              'New '
              'Roman\';font-size:10.5000pt;mso-font-kerning:1.0000pt;"><p></p></span></p></div>'],
 'job_responsibility': [''],
 'job_type': [''],
 'job_url': [''],
 'publish_time': ['1128'],
 'salary': ['1.5-3'],
 'title': ['Java/Python'],
 'work_years': ['']}
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5D79B0>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\pipelines.py", line 12, in process_item
    item.save_to_es()
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 57, in save_to_es
    job.suggest = gen_suggests(JobType._doc_type.index, ((job.title, 10), (job.job_city, 7)))
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 73, in gen_suggests
    words = es.indices.analyze(index=index, analyzer="ik_max_word", params={'filter': ["lowercase"]}, body=text)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "g:\anaconda\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 124, in perform_request
    raise ConnectionError('N/A', str(e), e)
elasticsearch.exceptions.ConnectionError: ConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5D79B0>: Failed to establish a new connection: [WinError 10061] ) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5D79B0>: Failed to establish a new connection: [WinError 10061] )
2019-11-29 16:39:48 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (57): localhost:9200
2019-11-29 16:39:50 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.016s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4780>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:50 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:50 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (58): localhost:9200
2019-11-29 16:39:52 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.000s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4E48>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:52 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:52 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (59): localhost:9200
2019-11-29 16:39:54 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.016s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4B70>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:54 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:54 [urllib3.util.retry] DEBUG: Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0, status=None)
2019-11-29 16:39:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (60): localhost:9200
2019-11-29 16:39:56 [elasticsearch] WARNING: GET http://localhost:9200/lagou/_analyze?filter=%5B%27lowercase%27%5D&analyzer=ik_max_word [status:N/A request:2.016s]
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4828>: Failed to establish a new connection: [WinError 10061] 
2019-11-29 16:39:56 [elasticsearch] DEBUG: > ["Python"]
2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error processing {'company_name': [''],
 'company_url': ['http://company.zhaopin.com/CZ872325800.htm'],
 'degree_need': [''],
 'job_advantage': [',,,,,,,'],
 'job_city': [''],
 'job_need': ['<div class="describtion__detail-content"><p '
              "style='margin-bottom: 0px; color: rgb(51, 51, 51); font-family: "
              '"microsoft yahei";\'></p><p style=\'margin-bottom: 0px; '
              'color: rgb(51, 51, 51); font-family: "microsoft '
              'yahei";\'>1</p><p style=\'margin-bottom: 0px; '
              'color: rgb(51, 51, 51); font-family: "microsoft '
              'yahei";\'>2</p><p style=\'margin-bottom: '
              '0px; color: rgb(51, 51, 51); font-family: "microsoft '
              'yahei";\'>3 </p><p style=\'margin-bottom: 0px; '
              'color: rgb(51, 51, 51); font-family: "microsoft '
              'yahei";\'>4</p><p style=\'margin-bottom: 0px; '
              'color: rgb(51, 51, 51); font-family: "microsoft '
              'yahei";\'><br></p><p style=\'margin-bottom: 0px; color: rgb(51, '
              '51, 51); font-family: "microsoft yahei";\'></p><p '
              "style='margin-bottom: 0px; color: rgb(51, 51, 51); font-family: "
              '"microsoft yahei";\'>1linux</p><p '
              "style='margin-bottom: 0px; color: rgb(51, 51, 51); font-family: "
              '"microsoft yahei";\'>2linux</p><p style=\'margin-bottom: '
              '0px; color: rgb(51, 51, 51); font-family: "microsoft '
              'yahei";\'>3</p></div>'],
 'job_responsibility': [''],
 'job_type': [''],
 'job_url': [''],
 'publish_time': ['10:41'],
 'salary': ['8-1'],
 'title': ['Python'],
 'work_years': ['']}
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 159, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 80, in create_connection
    raise err
  File "g:\anaconda\lib\site-packages\urllib3\util\connection.py", line 70, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 115, in perform_request
    response = self.pool.urlopen(method, url, body, retries=False, headers=self.headers, **kw)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "g:\anaconda\lib\site-packages\urllib3\util\retry.py", line 343, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "g:\anaconda\lib\site-packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "g:\anaconda\lib\site-packages\urllib3\connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "g:\anaconda\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "g:\anaconda\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "g:\anaconda\lib\http\client.py", line 964, in send
    self.connect()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 181, in connect
    conn = self._new_conn()
  File "g:\anaconda\lib\site-packages\urllib3\connection.py", line 168, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000003B4C5A4828>: Failed to establish a new connection: [WinError 10061] 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\pipelines.py", line 12, in process_item
    item.save_to_es()
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 57, in save_to_es
    job.suggest = gen_suggests(JobType._doc_type.index, ((job.title, 10), (job.job_city, 7)))
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\items.py", line 73, in gen_suggests
    words = es.indices.analyze(index=index, analyzer="ik_max_word", params={'filter': ["lowercase"]}, body=text)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "g:\anaconda\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "g:\anaconda\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "g:\anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 124, in perform_request
    raise ConnectionError('N/A', str(e), e)
elasticsearch.exceptions.ConnectionError: ConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5A4828>: Failed to establish a new connection: [WinError 10061] ) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x0000003B4C5A4828>: Failed to establish a new connection: [WinError 10061] )
2019-11-29 16:39:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC447954822J00406617303.htm"}
2019-11-29 16:39:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:39:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:39:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/239912717250164.htm"}
2019-11-29 16:39:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:39:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:39:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CZ896695330J00246985206.htm"}
2019-11-29 16:39:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:39:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:39:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC218653388J00387165003.htm"}
2019-11-29 16:39:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:39:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:39:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54302/session/fdb7d37a-28dd-4563-908c-4347aaedf287/url {"url": "https://jobs.zhaopin.com/CC824472920J00417432405.htm"}
2019-11-29 16:39:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54302 "POST /session/fdb7d37a-28dd-4563-908c-4347aaedf287/url HTTP/1.1" 404 123
2019-11-29 16:39:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC640402330J00378495702.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC120914506J00446169003.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC826330310J00327011508.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC191215511J00310135408.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC833252140J00274344707.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC645926286J00260826405.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CZ185718010J00196024502.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC465341913J00108419313.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CZ594912420J00305115703.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://xiaoyuan.zhaopin.com/job/CC000117819J90001986000?from=sz>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CCL1222977140J00450113003.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC542445930J00376959002.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC528943025J00441993307.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC833252140J00289577007.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC219838732J00353648902.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC219838732J00353649002.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC250519519J00365838608.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CZ697762580J00254850503.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/239912717250164.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC447954822J00406617303.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CZ896695330J00246985206.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC824472920J00417432405.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://jobs.zhaopin.com/CC218653388J00387165003.htm>
Traceback (most recent call last):
  File "g:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "g:\anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\asus\Desktop\\scrapy\zhisousou\zhisousou\middlewares.py", line 94, in process_request
    self.driver.get(request.url)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "g:\anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: Tried to run command without establishing a connection

2019-11-29 16:39:56 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-29 16:39:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 75,
 'downloader/exception_type_count/selenium.common.exceptions.InvalidSessionIdException': 74,
 'downloader/exception_type_count/selenium.common.exceptions.WebDriverException': 1,
 'downloader/response_bytes': 4560824,
 'downloader/response_count': 17,
 'downloader/response_status_count/200': 17,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 29, 8, 39, 56, 614701),
 'log_count/DEBUG': 582,
 'log_count/ERROR': 90,
 'log_count/INFO': 12,
 'log_count/WARNING': 60,
 'request_depth_max': 2,
 'response_received_count': 17,
 'scheduler/dequeued': 92,
 'scheduler/dequeued/memory': 92,
 'scheduler/enqueued': 92,
 'scheduler/enqueued/memory': 92,
 'start_time': datetime.datetime(2019, 11, 29, 8, 36, 33, 205259)}
2019-11-29 16:39:56 [scrapy.core.engine] INFO: Spider closed (finished)
